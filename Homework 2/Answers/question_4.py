# -*- coding: utf-8 -*-
"""question_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OF13oQ2k4OBbwyyDZmzXga_QiLptSlvN
"""

!pip install pyspark

#importing libraries
import numpy as np
import matplotlib.pyplot as plt
from scipy import linalg
import os
from pyspark import SparkContext

def mapper(line):
    lines = line.split(' ')
    list_of_lines = [float(i) for i in lines]
    return np.array(list_of_lines)

def reducer(row, centroids):
    distance = [(i, linalg.norm(row - center, 2)) for i, center in enumerate(centroids)]
    distance.sort(key=lambda k: k[-1])
    return (distance[0][0], (row, 1))

def cost_function(row, centroids):
    i, (d, n) = row
    distance = linalg.norm(d - centroids[i], 2)
    return distance**2

def plot(cost_1, cost_2):
    x = range(1, len(cost_1) + 1)

    plt.title('cost vs iteration', fontsize=15)
    plt.xlabel('iteration', fontsize=15)
    plt.ylabel('cost', fontsize=15)
    plt.plot(x, cost_1, color='blue', linewidth=2.0, linestyle='-',label="c1.txt")
    plt.plot(x, cost_2, color='red', linewidth=2.0, linestyle='-',label="c2.txt")
    plt.legend(loc='upper right')
    plt.savefig("4.png")
    plt.show()

if __name__ == '__main__':
    iter = 20
    sc = SparkContext.getOrCreate()
    path = 'data/data.txt'
    data = sc.textFile(path).map(lambda row:mapper(row)).cache()
    path1 = 'data/c1.txt'
    c1 = sc.textFile(path1).map(lambda row:mapper(row)).collect()
    path2 = 'data/c2.txt'
    c2 = sc.textFile(path2).map(lambda row:mapper(row)).collect()

    cost_1 = []
    cost_2 = []

    for i in range(iter):
        kmeans_1 = data.map(lambda row: reducer(row, c1))
        cost1 = kmeans_1.map(lambda row: cost_function(row, c1)).sum()
        cost_1.append(cost1)
        c1 = kmeans_1.reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1])) \
                     .map(lambda row: row[-1][0] / row[-1][1]).collect()

        kmeans_2 = data.map(lambda row: reducer(row, c2))
        cost2 = kmeans_2.map(lambda row: cost_function(row, c2)).sum()
        cost_2.append(cost2)
        c2 = kmeans_2.reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1])) \
                     .map(lambda row: row[-1][0] / row[-1][1]).collect()

    plot(cost_1, cost_2)

    print('Percentage change in cost after 10 iterations of the k-Means algorithm when the cluster centroids are initialized using c1.txt = ')
    print((cost_1[0]-cost_1[10])*100/cost_1[0], '\n')

    print('Percentage change in cost after 10 iterations of the k-Means algorithm when the cluster centroids are initialized using c2.txt = ')
    print((cost_2[0]-cost_2[10])*100/cost_2[0], '\n')